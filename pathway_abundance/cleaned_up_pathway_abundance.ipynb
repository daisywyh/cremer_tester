{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PATHWAY ABUNDANCE MANIPULATION\n",
    "\n",
    "This file focuses only on calculating relative pathway abundance, adding metadata, and cleaning up the data. \n",
    "\n",
    "This pipeline was last edited by Yu Han Daisy Wang on 28 August 2023."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## step 0: load all relevant/needed packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import font_manager"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## IF YOU'VE **ALREADY RAN** THIS PIPELINE AND HAVE DATA THAT'S ALREADY CLEANED UP, START HERE\n",
    "Use the following bit to load all of your data that's already been cleaned up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## IF YOU **HAVEN'T ALREADY RAN** THIS PIPELINE/YOU WANT TO CHANGE SOMETHING ABOUT THE DATA PROCESSING, START HERE\n",
    "This starts the data processing from scratch!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load all necessary data for starting from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bowtie hit summaries for propionate\n",
    "compiled_bt_hit_summaries_allpathways = pd.read_csv(\"compiled_bt_hit_summaries_allpathways.csv\")\n",
    "\n",
    "# gene lengths \n",
    "allpathways_gene_catalogue_seqlengths = pd.read_csv(\"allpathways_gene_catalogue_seqlengths.csv\").set_index(\"gene\")\n",
    "\n",
    "# gene information\n",
    "allpathways_gene_info = pd.read_csv(\"allpathways_genesInCatalogue_long.csv\")\n",
    "allpathways_gene_info = allpathways_gene_info.drop(allpathways_gene_info.columns[0], axis=1).set_index(\"strain_gene\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### gene length correction (new, using formula proposed by RC, step 1 of it)\n",
    "\n",
    "`gene_length_correction_new` performs the first half of the gene length correction process. Specifically, it does $hits\\;of\\;gene \\over length(gene)$. \n",
    "\n",
    "For reference, the full formula for our new gene length correction method is given as follows: $$\\frac{hits\\;of\\;gene}{hits\\;of\\;rplB \\cdot length(rplB) \\cdot length(gene)}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gene_length_correction_new(gene_catalogue_seqlengths, compiled_bt_hit_summaries):\n",
    "\n",
    "    gene_length_df = gene_catalogue_seqlengths\n",
    "\n",
    "    df = compiled_bt_hit_summaries.drop([\"pathway\"], axis=1).set_index(\"read_accession\")\n",
    "\n",
    "    new = df.copy()\n",
    "\n",
    "    # first replace the values in new with the gene length of that gene\n",
    "    for gene in compiled_bt_hit_summaries:\n",
    "        \n",
    "        if gene in gene_length_df.index:\n",
    "        \n",
    "            gene_length = gene_length_df.loc[gene].at[\"length\"]\n",
    "\n",
    "            new[gene] = [gene_length] * len(new)\n",
    "\n",
    "    # equivalent to hits of gene * length(gene)\n",
    "    new = df.div(new)\n",
    "\n",
    "    return new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### running the code for gene length correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "compiled_bt_hit_summaries_all_pathways_length_corrected = gene_length_correction_new(allpathways_gene_catalogue_seqlengths, compiled_bt_hit_summaries_allpathways)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### useful setup for calculating pathway abundances\n",
    "\n",
    "There's not much being done here, just some pure setup stuff that can be useful later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "abbreviations_dict = {\n",
    "    \"acetylCoA_buk\": \"Ace (buk)\",\n",
    "    \"acetylCoA_but\": \"Ace (but)\",\n",
    "    \"aminobutyrate_buk\": \"4-Ami (buk)\",\n",
    "    \"aminobutyrate_but\": \"4-Ami (but)\",\n",
    "    \"glutarate_buk\": \"Glu (buk)\",\n",
    "    \"glutarate_but\": \"Glu (but)\",\n",
    "    \"lysine\": \"Lys\",\n",
    "    \"sodium-pumping decarboxylase\": \"SP\",\n",
    "    \"Wood-Werkman Cycle\": \"WWC\",\n",
    "    \"acrylate pathway\": \"Acr\",\n",
    "    \"propanediol pathway\": \"Pro\"\n",
    "}\n",
    "\n",
    "pathway_length_dict = {\n",
    "    \"Ace (buk)\": 6,\n",
    "    \"Ace (but)\": 5,\n",
    "    \"4-Ami (buk)\": 6,\n",
    "    \"4-Ami (but)\": 5,\n",
    "    \"Glu (buk)\": 6,\n",
    "    \"Glu (but)\": 5,\n",
    "    \"Lys\": 7,\n",
    "    \"SP\": 4,\n",
    "    \"WWC\": 4,\n",
    "    \"Acr\": 3,\n",
    "    \"Pro\": 5\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calculating pathway abundances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `add_genes_in_catalogue` merges information about genes onto the hit table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_genes_in_catalogue(hit_table, gene_info, gene_catalogue_seqlengths):\n",
    "\n",
    "    temp = hit_table.transpose()\n",
    "\n",
    "    # this merges the information about the genes into the hit table\n",
    "    temp = temp.merge(gene_info, how=\"left\", left_index=True, right_index=True)\n",
    "\n",
    "    # everything after this is purely cosmetic, it just moves the columns strain, pathway, \n",
    "    # gene, strain_pathway, and length to the front \n",
    "    strain = temp.pop(\"strain\")\n",
    "    temp.insert(0, strain.name, strain)\n",
    "\n",
    "    pathway = temp.pop(\"pathway\")\n",
    "    temp.insert(1, pathway.name, pathway)\n",
    "\n",
    "    gene = temp.pop(\"gene\")\n",
    "    temp.insert(2, gene.name, gene)\n",
    "\n",
    "    strain_pathway = temp.pop(\"strain_pathway\")\n",
    "    temp.insert(3, strain_pathway.name, strain_pathway)\n",
    "\n",
    "    temp = temp.merge(gene_catalogue_seqlengths, how=\"left\", left_index=True, right_index=True)\n",
    "\n",
    "    length = temp.pop(\"length\")\n",
    "    temp.insert(4, length.name, length)\n",
    "\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_hit_table = add_genes_in_catalogue(compiled_bt_hit_summaries_all_pathways_length_corrected, allpathways_gene_info, allpathways_gene_catalogue_seqlengths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### part 2 of length correction: dividing by number of hits for rplB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def length_correction_denominator(hit_table):\n",
    "\n",
    "    grouped = hit_table.groupby(\"strain_pathway\").sum().drop([\"strain\", \"pathway\", \"gene\", \"length\"], axis=1)\n",
    "\n",
    "    rplB_sum = grouped.loc[\"housekeeping\"]\n",
    "\n",
    "    not_samples = [\"strain\", \"pathway\", \"gene\", \"strain_pathway\", \"length\"]\n",
    "\n",
    "    new = hit_table.copy\n",
    "\n",
    "    for read in grouped:\n",
    "\n",
    "        hit_table[read] /= rplB_sum[read]\n",
    "\n",
    "    return hit_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_hit_table = length_correction_denominator(final_hit_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### this step is to normalise by proportion for the unknown samples\n",
    "\n",
    "The formula for this normalisation is given as follows. Let $x$ be the amount of the mixed sample, $S_n$ be the known we are trying to approximate, and $S_i$ be the $i$-th known sample that is in the mixed sample. Let there be $n$ known samples in the mixed sample. As such, the total amount of $S_n$ can be given as follows:\n",
    "\n",
    "$$actual\\;amount\\;of\\;S_n = \\frac{S_n}{\\sum_{i=1}^{n} S_i} \\cdot x$$\n",
    "\n",
    "A function to perform this normalisation is given below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise_unknown(df):\n",
    "\n",
    "    # this function does not operate in place. instead, it returns a modified copy of the original dataframe.\n",
    "    new = df.copy()\n",
    "\n",
    "    # This dictionary stores all of the names of the pathways that are unclear\n",
    "    unknown_samples = {\n",
    "        \"acetylCoA_buk or glutarate_buk\": [\"acetylCoA_buk\", \"glutarate_buk\"],\n",
    "        \"aminobutyrate_but or acetylCoA_but\": [\"aminobutyrate_but\", \"acetylCoA_but\"],\n",
    "        \"acetylCoA_buk or lysine\": [\"acetylCoA_buk\", \"lysine\"],\n",
    "        \"acetylCoA_but or glutarate_but\": [\"acetylCoA_but\", \"glutarate_but\"],\n",
    "        \"acetylCoA_but or glutarate_but or lysine\": [\"acetylCoA_but\", \"glutarate_but\", \"lysine\"],\n",
    "        \"acetylCoA_but or lysine\": [\"acetylCoA_but\", \"lysine\"],\n",
    "        \"aminobutyrate_buk or acetylCoA_buk\": [\"aminobutyrate_buk\", \"acetylCoA_buk\"],\n",
    "        \"aminobutyrate_buk or acetylCoA_buk or lysine\": [\"aminobutyrate_buk\", \"acetylCoA_buk\", \"lysine\"],\n",
    "        \"aminobutyrate_buk or lysine\": [\"aminobutyrate_buk\", \"lysine\"],\n",
    "        \"aminobutyrate_but or acetylCoA_but\": [\"aminobutyrate_but\", \"acetylCoA_but\"],\n",
    "        \"aminobutyrate_but or acetylCoA_but or glutarate_but\": [\"aminobutyrate_but\", \"acetylCoA_but\", \"glutarate_but\"]\n",
    "    }\n",
    "\n",
    "    # for each sample, loop through each pathway in the sample\n",
    "    for sample in df:\n",
    "\n",
    "        for pathway in list(df.index):\n",
    "\n",
    "            # this is my way of finding all the pathways that are ambigious\n",
    "            if \" or \" in pathway:\n",
    "\n",
    "                # this just gets the raw number of hits for the ambigious sample\n",
    "                unknown_proportion = df.loc[pathway].at[sample]\n",
    "\n",
    "                # if the raw number of hits == 0, exit this loop\n",
    "                # if the loop is not exited, this will cause a divide by 0 error later\n",
    "                if unknown_proportion == 0: break\n",
    "\n",
    "                # setup for the rest of the calculations\n",
    "                components_list = unknown_samples[pathway]\n",
    "                proportion_dict = {}\n",
    "                denominator = 0\n",
    "                \n",
    "                # for every component in the unkonwn samples\n",
    "                # if it's != 0, add add it to the denominator\n",
    "                for component in components_list:\n",
    "\n",
    "                    if df.loc[component].at[sample] != 0:\n",
    "\n",
    "                        proportion_dict[component] = df.loc[component].at[sample]\n",
    "                        denominator += proportion_dict[component]\n",
    "\n",
    "                # if there ends up being more than one type of sample in the unknown mixture\n",
    "                # actually do the calculations\n",
    "                # if there's only one, don't bother\n",
    "                if len(proportion_dict) > 1:\n",
    "\n",
    "                    for component in components_list:\n",
    "\n",
    "                        new.loc[component].at[sample] = proportion_dict[component] + ((proportion_dict[component] / denominator) * unknown_proportion)\n",
    "\n",
    "    new = new.drop(list(unknown_samples.keys()))\n",
    "\n",
    "    return new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, actually implement the `normalisation_unknown` function on actual data\n",
    "\n",
    "First, perform some preprocessing of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_pathway_group = final_hit_table.groupby([\"strain_pathway\"]).sum()\n",
    "\n",
    "overall_pathway_group = overall_pathway_group.drop([\"strain\", \"pathway\", \"gene\", \"length\"], axis=1).drop([\"housekeeping\"], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, actually implement everything. The code for parsing out the unknown proportions is not very well written, so this section might take a long time to run, as long as just under 10 minutes. For context, the last time I tried to run this chunk, it took me 7 mins and 31 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalised_unknown_overall_pathway_group = normalise_unknown(overall_pathway_group)\n",
    "\n",
    "# the next two steps are purely for aesthetic reasons\n",
    "# it just orders it so that the propionate and butyrate pathways are together\n",
    "normalised_unknown_overall_pathway_group = normalised_unknown_overall_pathway_group.transpose()\n",
    "normalised_unknown_overall_pathway_group = normalised_unknown_overall_pathway_group.reindex(columns= [\"acetylCoA_buk\", \"acetylCoA_but\", \"aminobutyrate_buk\", \"aminobutyrate_but\", \"glutarate_buk\", \"glutarate_but\", \"lysine\", \"sodium-pumping decarboxylase\", \"Wood-Werkman Cycle\", \"acrylate pathway\", \"propanediol pathway\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fixing column names to the abbreviations\n",
    "\n",
    "this next step just changes things from the raw names to the abbreviations established earlier. It does this by looping through the `abbreviations_dict` established earlier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in normalised_unknown_overall_pathway_group:\n",
    "    normalised_unknown_overall_pathway_group.rename(columns = {column:abbreviations_dict[column]}, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### normalisation with respect to the length of each pathway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pathway in normalised_unknown_overall_pathway_group:\n",
    "\n",
    "    # if the pathway is in our pathway_length_dict (it should be, this step is just to make sure)\n",
    "    # then divide the abundance by the length of that pathway\n",
    "    if pathway in pathway_length_dict.keys():\n",
    "\n",
    "        normalised_unknown_overall_pathway_group[pathway] /= pathway_length_dict[pathway]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### now add what the actual final pathways are\n",
    "\n",
    "This part simply goes through the entire file/column to figure out what pathway produces, then appends this result to the given table.\n",
    "\n",
    "The input table should have the **pathways** as the index, and the **samples** as the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_pathway(df):\n",
    "\n",
    "    new = df.copy()\n",
    "\n",
    "    prop_pathways = [\"SP\", \"WWC\", \"Pro\", \"Acr\"]\n",
    "\n",
    "    butyrate_pathways = [\"Ace (buk)\", \"4-Ami (buk)\", \"Lys\", \"Glu (but)\", \"Glu (buk)\", \"Ace (but)\", \"4-Ami (but)\"]\n",
    "\n",
    "    pathway_result = []\n",
    "\n",
    "    # for each pathway in \n",
    "    for path in list(new.index):\n",
    "\n",
    "        if path in prop_pathways: pathway_result.append(\"PROP\")\n",
    "\n",
    "        if path in butyrate_pathways: pathway_result.append(\"BTR\")\n",
    "\n",
    "    new.insert(0, \"overall_pathway\", pathway_result)\n",
    "\n",
    "    return new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the function `find_pathway` to the table `normalised_unknown_overall_pathway_group`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "prop_but_groupby = find_pathway(normalised_unknown_overall_pathway_group.transpose()).groupby([\"overall_pathway\"]).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### add the stuff about metadata + species \n",
    "\n",
    "This code is taken directly from August Burton, who I believe might have first gotten this code from Rebecca Christesen (RC)? Either way, all this code does is get you one final table that you need to care about (`relab2`), which contains taxonomical information for what I believe to be most, if not all, samples from the curated metagenomics dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2696027/2769290257.py:8: DtypeWarning: Columns (21,22,27,29,30,33,36,43,50,52,53,54,55,56,57,62,63,70,72,76,77,87,90,98,99,102,106,107,108,109,111,114,115,116,123) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  colnames=pd.read_csv(\"data_curated_microbiome/relabundance_colData.csv\")\n"
     ]
    }
   ],
   "source": [
    "# Load curated microbiome data\n",
    "# The original data is provided in R. Here, we use only the abundance data, provided in easily to handle csv files (subfolder data_curated_microbiome). The abundance levels were extracted from metagenomics using https://github.com/biobakery/MetaPhlAn.\n",
    "#big table with abundance of different species across all thousands of samples from the data collection\n",
    "relab=pd.read_csv(\"data_curated_microbiome/relabundance.csv\")\n",
    "relab.rename(columns={'Unnamed: 0': 'tax_identifier'},inplace=True) # Gives first column label \"tax_identifier\"\n",
    "\n",
    "#information about samples\n",
    "colnames=pd.read_csv(\"data_curated_microbiome/relabundance_colData.csv\")\n",
    "colnames.rename(columns={'Unnamed: 0': 'sample'},inplace=True) # Gives name to first column\n",
    "\n",
    "#information about different species detected in the different samples\n",
    "rownames=pd.read_csv(\"data_curated_microbiome/relabundance_rowData.csv\")\n",
    "rownames.rename(columns={'Unnamed: 0': 'tax_identifier'},inplace=True)\n",
    "\n",
    "#add species information to major data table. Used for groupby analysis later on\n",
    "relab2 = relab.merge(rownames, on='tax_identifier', how='inner')  # Rows = species, Cols = Samples + species info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding metadata into it all\n",
    "\n",
    "This adds metadata to both the versions where we've grouped by prop vs btr already (`with_metadata_prop_but_normalised`), or we're still at the pathway level (`with_metadata_overall_group_normalised`). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = pd.read_csv(\"data_curated_microbiome/nayfach_asnicar_hmp_metadata.csv\").set_index(\"NCBI_accession\")\n",
    "\n",
    "temp = prop_but_groupby.transpose()\n",
    "\n",
    "with_metadata_prop_but_normalised = temp.merge(metadata, how=\"left\", left_index=True, right_index=True)\n",
    "\n",
    "with_metadata_prop_but_normalised.to_csv(\"output/with_metadata_prop_but_normalised.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = normalised_unknown_overall_pathway_group\n",
    "\n",
    "with_metadata_overall_group_normalised = temp.merge(metadata, how=\"left\", left_index=True, right_index=True)\n",
    "\n",
    "with_metadata_overall_group_normalised.to_csv(\"output/with_metadata_overall_group_normalised.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **RELOAD DATA HERE! RELOAD THE FIRST VERSION OF DATA METADATA!!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_metadata_prop_but_normalised = pd.read_csv(\"output/with_metadata_prop_but_normalised.csv\").set_index(\"Unnamed: 0.1\")\n",
    "\n",
    "with_metadata_overall_group_normalised = pd.read_csv(\"output/with_metadata_overall_group_normalised.csv\").set_index(\"Unnamed: 0.1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### now lets normalise for percentage\n",
    "\n",
    "Both of these functions simply convert everything from regular stuff to percentages.\n",
    "\n",
    "`percentageNormaliseOne` does normalisation correctly if there is no metadata attached. It requires the given data to have the **pathways** as the index, and the **samples** as the columns.\n",
    "\n",
    "`percentageNormaliseTwo` does normalisation correctly only if there is metadata attached. It requires teh given data to have the **samples** as the index, and **pathways** as the columns. It also accounts for the case of dividing by 0, in which it just fills in `np.nan`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def percentageNormaliseOne(df):\n",
    "\n",
    "    new = df.copy()\n",
    "\n",
    "    summed = df.sum(axis=0)\n",
    "\n",
    "    for row in df.index:\n",
    "\n",
    "        new.loc[row] = df.loc[row].div(summed)\n",
    "\n",
    "    return new\n",
    "\n",
    "def percentageNormaliseTwo(df, pathways):\n",
    "\n",
    "    summed = df[pathways[0]].add(df[pathways[1]])\n",
    "\n",
    "    for pathway in pathways:\n",
    "\n",
    "        pathway_name = pathway+\"_percent\"\n",
    "        \n",
    "        df[pathway_name] = df[pathway].div(summed)\n",
    "\n",
    "        df.loc[~np.isfinite(df[pathway_name]), pathway_name] = np.nan\n",
    "\n",
    "    return df.transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Percentage normalisation in actiion\n",
    "\n",
    "The following applies the percentage normalisation function to all of the actual data. \n",
    "\n",
    "Note: here, I included these two metrics: `BTR % - PROP %` and `BTR - PROP`. I highly advise against using these metrics, as I don't think that they add anything of value to our analysis. The metrics are as follows:\n",
    "- `BTR % - PROP %` is the percentage of BTR pathways minus the percentage of PROP pathways. \n",
    "- `BTR - PROP` is the raw relative abundance of BTR pathways minus the percentage of PROP pathways\n",
    "\n",
    "Otherwise, the percentages are listed under "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_metadata_prop_but_percent_change = percentageNormaliseTwo(with_metadata_prop_but_normalised, [\"BTR\", \"PROP\"])\n",
    "\n",
    "with_metadata_prop_but_percent_change.loc[\"BTR % - PROP %\"] = with_metadata_prop_but_percent_change.loc[\"BTR_percent\"] - with_metadata_prop_but_percent_change.loc[\"PROP_percent\"]\n",
    "\n",
    "with_metadata_prop_but_percent_change.loc[\"BTR - PROP\"] = with_metadata_prop_but_percent_change.loc[\"BTR\"] - with_metadata_prop_but_percent_change.loc[\"PROP\"]\n",
    "\n",
    "with_metadata_prop_but_percent_change = with_metadata_prop_but_percent_change.transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This adds my own binning for age. I felt like the way that binning was done for the data wasn't very useful, so I redid the binning according to NIH style guidelines (https://www.nih.gov/nih-style-guide/age)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_category_list = []\n",
    "\n",
    "index = 0\n",
    "\n",
    "# go through every sample to get their age, and bin it accordingly\n",
    "for sample in with_metadata_prop_but_percent_change.age:\n",
    "\n",
    "    if sample <=1:\n",
    "        if with_metadata_prop_but_percent_change.infant_age[index] <= 30:\n",
    "            age_category_list.append(\"Newborn\\n≤ 1 month\")\n",
    "        else:\n",
    "            age_category_list.append(\"Infant\\n(1 month to 1 year)\")\n",
    "\n",
    "    elif sample > 1 and sample <=12: age_category_list.append(\"Child\\n(1 to 12 years)\")\n",
    "\n",
    "    elif sample > 12 and sample < 18: age_category_list.append(\"Adolescent\\n(13 to 17 years)\")\n",
    "\n",
    "    elif sample >= 18 and sample < 65: age_category_list.append(\"Adult\\n≥ 18 years\")\n",
    "\n",
    "    elif sample >= 65: age_category_list.append(\"Older Adult\\n≥ 65\")\n",
    "\n",
    "    else: age_category_list.append(np.nan)\n",
    "\n",
    "    index += 1\n",
    "\n",
    "# update the age_category column with the correct values\n",
    "with_metadata_prop_but_percent_change[\"age_category\"] = age_category_list\n",
    "\n",
    "# fix the \"infant_age\" column name to be \"Infant Age (days)\" instead\n",
    "with_metadata_prop_but_percent_change = with_metadata_prop_but_percent_change.rename(columns={\"infant_age\": \"Infant Age (days)\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### adjusting names\n",
    "\n",
    "This function just changes values in a specified column based on the input of a dictionary. This is more for if we need to fix up how some of the metadata is labelled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_values(df, old_column_name, new_column_name, adjust_dict):\n",
    "    \"\"\"\n",
    "    df = the dataframe that you wish to fix\n",
    "    old_column_name = the name of the column with wrong values\n",
    "    new_column_name = new name of the column\n",
    "    adjust_dict = a dictionary with the keys as the original values in the columns,\n",
    "    and the values of each key as the name you wish to change the key to. make sure\n",
    "    to add one last entry of np.nan: np.nan in the dictionary\n",
    "    \"\"\"\n",
    "\n",
    "    adjusted_list = []\n",
    "\n",
    "    for curr in df[old_column_name]:\n",
    "        adjusted_list.append(adjust_dict[curr])\n",
    "\n",
    "    df[old_column_name] = adjusted_list\n",
    "\n",
    "    df = df.rename(columns={old_column_name: new_column_name})\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feeding_practice_names = {\n",
    "    \"exclusively_breastfeeding\": \"Exclusively\\nBreastfeeding\",\n",
    "    \"mixed_feeding\": \"Mixed\\nFeeding\",\n",
    "    \"any_breastfeeding\": \"Any\\nBreastfeeding\",\n",
    "    \"no_breastfeeding\": \"No\\nBreastfeeding\",\n",
    "    \"exclusively_formula_feeding\": \"Exclusively\\nFormula\\nFeeding\",\n",
    "    np.nan: np.nan\n",
    "}\n",
    "\n",
    "with_metadata_prop_but_percent_change = adjust_values(with_metadata_prop_but_percent_change, \"feeding_practice\", \"Feeding Practice\", feeding_practice_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now save everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_metadata_prop_but_percent_change.to_csv(\"output/with_metadata_prop_but_percent_change.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RELOAD THE DATA HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_metadata_prop_but_percent_change = pd.read_csv(\"output/with_metadata_prop_but_percent_change.csv\").set_index(\"Unnamed: 0.1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "healthy_overall_group_noramlised = with_metadata_overall_group_normalised.loc[with_metadata_overall_group_normalised['disease'] == \"healthy\"]\n",
    "\n",
    "healthy_prop_but_noramlised = with_metadata_prop_but_percent_change.loc[with_metadata_prop_but_percent_change['disease'] == \"healthy\"]\n",
    "\n",
    "adult_healthy_overall_group_normalised = healthy_overall_group_noramlised.loc[healthy_overall_group_noramlised[\"age\"] >= 18]\n",
    "\n",
    "adult_health_prop_but_normalised = with_metadata_prop_but_percent_change.loc[with_metadata_prop_but_percent_change[\"age\"] >= 18]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### add the taxonomical information in\n",
    "\n",
    "This code is taken directly from August Burton, who I believe might have first gotten this code from Rebecca Christesen (RC)? Either way, all this code does is get you one final table that you need to care about (`relab2`), which contains taxonomical information for what I believe to be most, if not all, samples from the curated metagenomics dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2696027/2769290257.py:8: DtypeWarning: Columns (21,22,27,29,30,33,36,43,50,52,53,54,55,56,57,62,63,70,72,76,77,87,90,98,99,102,106,107,108,109,111,114,115,116,123) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  colnames=pd.read_csv(\"data_curated_microbiome/relabundance_colData.csv\")\n"
     ]
    }
   ],
   "source": [
    "# Load curated microbiome data\n",
    "# The original data is provided in R. Here, we use only the abundance data, provided in easily to handle csv files (subfolder data_curated_microbiome). The abundance levels were extracted from metagenomics using https://github.com/biobakery/MetaPhlAn.\n",
    "#big table with abundance of different species across all thousands of samples from the data collection\n",
    "relab=pd.read_csv(\"data_curated_microbiome/relabundance.csv\")\n",
    "relab.rename(columns={'Unnamed: 0': 'tax_identifier'},inplace=True) # Gives first column label \"tax_identifier\"\n",
    "\n",
    "#information about samples\n",
    "colnames=pd.read_csv(\"data_curated_microbiome/relabundance_colData.csv\")\n",
    "colnames.rename(columns={'Unnamed: 0': 'sample'},inplace=True) # Gives name to first column\n",
    "\n",
    "#information about different species detected in the different samples\n",
    "rownames=pd.read_csv(\"data_curated_microbiome/relabundance_rowData.csv\")\n",
    "rownames.rename(columns={'Unnamed: 0': 'tax_identifier'},inplace=True)\n",
    "\n",
    "#add species information to major data table. Used for groupby analysis later on\n",
    "relab2 = relab.merge(rownames, on='tax_identifier', how='inner')  # Rows = species, Cols = Samples + species info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>NCBI_accession</th>\n",
       "      <th>ERR4330026</th>\n",
       "      <th>ERR4330027</th>\n",
       "      <th>ERR4330028</th>\n",
       "      <th>ERR4330029</th>\n",
       "      <th>ERR4330030</th>\n",
       "      <th>ERR4330031</th>\n",
       "      <th>ERR4330032</th>\n",
       "      <th>ERR4330033</th>\n",
       "      <th>ERR4330034</th>\n",
       "      <th>ERR4330035</th>\n",
       "      <th>...</th>\n",
       "      <th>NaN</th>\n",
       "      <th>NaN</th>\n",
       "      <th>NaN</th>\n",
       "      <th>NaN</th>\n",
       "      <th>NaN</th>\n",
       "      <th>NaN</th>\n",
       "      <th>NaN</th>\n",
       "      <th>NaN</th>\n",
       "      <th>NaN</th>\n",
       "      <th>NaN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Firmicutes</th>\n",
       "      <td>27.71216</td>\n",
       "      <td>41.37050</td>\n",
       "      <td>43.70317</td>\n",
       "      <td>33.88667</td>\n",
       "      <td>59.64222</td>\n",
       "      <td>43.99187</td>\n",
       "      <td>31.28870</td>\n",
       "      <td>64.93870</td>\n",
       "      <td>47.43638</td>\n",
       "      <td>19.93554</td>\n",
       "      <td>...</td>\n",
       "      <td>16.59618</td>\n",
       "      <td>10.50896</td>\n",
       "      <td>14.46574</td>\n",
       "      <td>24.15066</td>\n",
       "      <td>31.21463</td>\n",
       "      <td>44.78141</td>\n",
       "      <td>36.31200</td>\n",
       "      <td>59.3616</td>\n",
       "      <td>68.22818</td>\n",
       "      <td>35.96867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bacteroidetes</th>\n",
       "      <td>64.86127</td>\n",
       "      <td>54.68318</td>\n",
       "      <td>34.64965</td>\n",
       "      <td>61.13726</td>\n",
       "      <td>35.83284</td>\n",
       "      <td>48.15292</td>\n",
       "      <td>63.60274</td>\n",
       "      <td>32.86029</td>\n",
       "      <td>36.27032</td>\n",
       "      <td>68.64813</td>\n",
       "      <td>...</td>\n",
       "      <td>80.57261</td>\n",
       "      <td>85.14478</td>\n",
       "      <td>83.65760</td>\n",
       "      <td>75.27369</td>\n",
       "      <td>67.96384</td>\n",
       "      <td>48.82434</td>\n",
       "      <td>59.20388</td>\n",
       "      <td>36.2418</td>\n",
       "      <td>31.06421</td>\n",
       "      <td>59.77691</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 1317 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "NCBI_accession  ERR4330026  ERR4330027  ERR4330028  ERR4330029  ERR4330030  \\\n",
       "Firmicutes        27.71216    41.37050    43.70317    33.88667    59.64222   \n",
       "Bacteroidetes     64.86127    54.68318    34.64965    61.13726    35.83284   \n",
       "\n",
       "NCBI_accession  ERR4330031  ERR4330032  ERR4330033  ERR4330034  ERR4330035  \\\n",
       "Firmicutes        43.99187    31.28870    64.93870    47.43638    19.93554   \n",
       "Bacteroidetes     48.15292    63.60274    32.86029    36.27032    68.64813   \n",
       "\n",
       "NCBI_accession  ...       NaN       NaN       NaN       NaN       NaN  \\\n",
       "Firmicutes      ...  16.59618  10.50896  14.46574  24.15066  31.21463   \n",
       "Bacteroidetes   ...  80.57261  85.14478  83.65760  75.27369  67.96384   \n",
       "\n",
       "NCBI_accession       NaN       NaN      NaN       NaN       NaN  \n",
       "Firmicutes      44.78141  36.31200  59.3616  68.22818  35.96867  \n",
       "Bacteroidetes   48.82434  59.20388  36.2418  31.06421  59.77691  \n",
       "\n",
       "[2 rows x 1317 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this takes only the phylum level data, as currently that's what we care the most about\n",
    "# however, please feel free to modify this as needed/as you would like\n",
    "phylum_df = relab2.groupby(\"phylum\").sum().drop([\"superkingdom\", \"class\", \"order\", \"family\", \"genus\", \"species\"], axis=1).reset_index().set_index(\"phylum\").drop([\"tax_identifier\"], axis=1)\n",
    "\n",
    "temp = phylum_df.transpose()\n",
    "\n",
    "metadata = pd.read_csv(\"data_curated_microbiome/nayfach_asnicar_hmp_metadata.csv\").drop([\"infant_age\", \"age_category\", \"gender\", \"country\", \"non_westernized\", \"BMI\"], axis=1).set_index(\"Unnamed: 0\")\n",
    "\n",
    "with_phylum = metadata.merge(temp, how=\"left\", left_index=True, right_index=True).reset_index().set_index(\"NCBI_accession\")\n",
    "\n",
    "with_phylum.to_csv(\"output/with_phylum.csv\")\n",
    "\n",
    "# get only Bacteroidetes and Firmicutes\n",
    "bacteroidetes_vs_firmicutes = with_phylum[[\"Bacteroidetes\", \"Firmicutes\"]]\n",
    "\n",
    "bacteroidetes_vs_firmicutes = bacteroidetes_vs_firmicutes.reindex([\"Firmicutes\", \"Bacteroidetes\"], axis=\"columns\").transpose()\n",
    "\n",
    "adult_healthy_bacteroidetes_vs_firmicutes = with_phylum[[\"Bacteroidetes\", \"Firmicutes\", \"age\", \"disease\"]]\n",
    "\n",
    "adult_healthy_bacteroidetes_vs_firmicutes = adult_healthy_bacteroidetes_vs_firmicutes.loc[adult_healthy_bacteroidetes_vs_firmicutes[\"age\"] >= 18]\n",
    "\n",
    "adult_healthy_bacteroidetes_vs_firmicutes = adult_healthy_bacteroidetes_vs_firmicutes.loc[adult_healthy_bacteroidetes_vs_firmicutes[\"disease\"] == \"healthy\"]\n",
    "\n",
    "adult_healthy_bacteroidetes_vs_firmicutes = adult_healthy_bacteroidetes_vs_firmicutes.drop([\"age\", \"disease\"], axis=1).reindex([\"Firmicutes\", \"Bacteroidetes\"], axis=\"columns\").transpose()\n",
    "\n",
    "adult_healthy_bacteroidetes_vs_firmicutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_samples = adult_healthy_bacteroidetes_vs_firmicutes.transpose().reset_index().dropna()\n",
    "\n",
    "valid_samples = valid_samples.set_index(\"NCBI_accession\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = adult_health_prop_but_normalised[[\"BTR\", \"PROP\"]]\n",
    "\n",
    "adult_health_prop_but_percent = percentageNormaliseOne(temp.transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_merged = adult_health_prop_but_percent.transpose().merge(valid_samples, how=\"left\", left_index=True, right_index=True)\n",
    "\n",
    "temp_merged = percentageNormaliseTwo(temp_merged, [\"Firmicutes\", \"Bacteroidetes\"])\n",
    "\n",
    "temp_merged = temp_merged.transpose().sort_values(\"Firmicutes_percent\")\n",
    "\n",
    "sorted_adult_healthy_bacteroidetes_vs_firmicutes_percent = temp_merged[[\"Firmicutes_percent\", \"Bacteroidetes_percent\"]].transpose()\n",
    "\n",
    "sorted_adult_healthy_prop_but_percent = temp_merged[[\"BTR\", \"PROP\"]].transpose()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.4 ('pathway_abundance')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fe830e55702ed5d1a418e856f39da784e7da7ed40fb81b27836f6ec2261e36fe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
